apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: obfuscator-mutate-
spec:
  entrypoint: obfuscator-mutate
  parallelism: 10
  arguments:
    parameters:
    - name: attempts
    - name: treesize
    - name: peek
    - name: file
    - name: oracle
  templates:
  - name: obfuscator-mutate
    steps:
    - - name: execute-analyzer
        template: analyzer-template
        arguments:
          parameters:
          - name: features
            value: "{{item.features}}"
          - name: dbconn
            value: "{{item.dbconn}}"
          - name: key
            value: "{{= sprig.regexReplaceAll( '[///._ ]', workflow.parameters.file,'-')}}-{{= sprig.regexReplaceAll( '[///._ ]', workflow.parameters.oracle,'-')}}-{{= sprig.regexReplaceAll('[///./,_]',item.features, '-')}}"
        withItems:
          - { dbconn: "all_Ikarus", features: "wasm-mutate/all" }

          # - { dbconn: "c78_simple", features: "wasm-mutate/add_function" }
          # - { dbconn: "c79_simple", features: "wasm-mutate/add_type" }
          
        continueOn:
          failed: true
   
  - name: analyzer-template
    
    retryStrategy:
      limit: 3
    inputs:
      parameters:
      - name: dbconn
      - name: features
      - name: key
      artifacts:
      - name: data
        path: /input.wasm
        archive:
          none: {}
        s3:
          bucket: my-bucket
          endpoint: minio-service.minio:3434
          insecure: true
          # Avoid to mount the full metas_filtered folder in the container
          key: "filtered/{{workflow.parameters.file}}"
          accessKeySecret:
            name: argo-artifacts
            key: accesskey
          secretKeySecret:
            name: argo-artifacts
            key: secretkey
    outputs:
      artifacts:
      - name: data
        path: /{{inputs.parameters.dbconn}}.zip
        optional: true
        archive:
          none: {}
        s3:
          bucket: my-bucket
          endpoint: minio-service.minio:3434
          insecure: true
          # Avoid to mount the full metas_filtered folder in the container
          key: "data/vt/mutate_datas/{{workflow.parameters.file}}/{{inputs.parameters.dbconn}}.zip"
          accessKeySecret:
            name: argo-artifacts
            key: accesskey
          secretKeySecret:
            name: argo-artifacts
            key: secretkey
      - name: logs
        path: /{{inputs.parameters.dbconn}}.logs.txt
        optional: true
        archive:
          none: {}
        s3:
          bucket: my-bucket
          endpoint: minio-service.minio:3434
          insecure: true
          # Avoid to mount the full metas_filtered folder in the container
          key: "data/vt/logs_mutate/{{workflow.parameters.file}}/{{inputs.parameters.dbconn}}.logs.txt"
          accessKeySecret:
            name: argo-artifacts
            key: accesskey
          secretKeySecret:
            name: argo-artifacts
            key: secretkey
      - name: stats
        path: /{{inputs.parameters.dbconn}}.stats.txt
        optional: true
        archive:
          none: {}
        s3:
          bucket: my-bucket
          endpoint: minio-service.minio:3434
          insecure: true
          # Avoid to mount the full metas_filtered folder in the container
          key: "data/vt/logs_mutate/{{workflow.parameters.file}}/{{inputs.parameters.dbconn}}.stats.txt"
          accessKeySecret:
            name: argo-artifacts
            key: accesskey
          secretKeySecret:
            name: argo-artifacts
            key: secretkey
    script:
    
      image: jacarte/obf-image:687cfe1
      command: [bash]
      resources:
        requests:
          memory: "0"
          cpu: 2
      source: |
         # Install mc client to save snapshot
          mkdir -p $HOME/minio-binaries
          wget -O $HOME/minio-binaries/mc https://dl.min.io/client/mc/release/linux-amd64/mc
          ls
          echo "======"
          chmod +x $HOME/minio-binaries/mc
          export PATH=$PATH:$HOME/minio-binaries/
         
          mc config host add exp http://minio-service.minio:3434 minio minio123

          
          if [[  $(mc ls exp/my-bucket/data/vt/mutate_datas/{{workflow.parameters.file}}/{{inputs.parameters.dbconn}}.zip | wc -l) -gt 0 ]]
          then
            echo "Already exist. Skip"
            exit 0
          fi

          # Now copy this into /wasms

         # Update with latest version
         git pull
         git submodule update --recursive

         ls -R ../oracles
         pip3 install -r ../oracles/requirements.txt

         # Ok compile the right version
         $HOME/.cargo/bin/cargo build --release --features "{{inputs.parameters.features}}" 

          # launch watchdog
          touch "{{inputs.parameters.dbconn}}.stats.txt"
          #bash watchdog_interval.sh "{{inputs.parameters.dbconn}}.stats.txt" 60 {{workflow.parameters.file}} &
          watchID=$!

          touch "{{inputs.parameters.dbconn}}.logs.txt"
          #bash watchdog_interval.sh "{{inputs.parameters.dbconn}}.logs.txt" 60 {{workflow.parameters.file}} &
          watchID2=$!

         echo "Oracle {{workflow.parameters.oracle}}"
         RUST_LOG=analyzer=debug ./target/release/analyzer --dbconn "datas/{{inputs.parameters.dbconn}}" mutate -s {{workflow.parameters.treesize}} -e --attempts {{workflow.parameters.attempts}} -p {{workflow.parameters.peek}}  --input /input.wasm --oracle {{workflow.parameters.oracle}} 1> {{inputs.parameters.dbconn}}.stats.txt 2> {{inputs.parameters.dbconn}}.logs.txt 
         
         #kill -9 $watchID
         #kill -9 $watchID2

         cp {{inputs.parameters.dbconn}}.logs.txt  /{{inputs.parameters.dbconn}}.logs.txt 
         cp {{inputs.parameters.dbconn}}.stats.txt  /{{inputs.parameters.dbconn}}.stats.txt 
         cp probes.logs.txt datas/{{inputs.parameters.dbconn}}
         cat /{{inputs.parameters.dbconn}}.stats.txt 
         # Now save the datas folder
         7z a  -tzip /{{inputs.parameters.dbconn}}.zip "datas/"